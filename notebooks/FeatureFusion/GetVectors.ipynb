{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9d3e5b5-b62a-4bc0-880e-2e2305228123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07210a8-af1d-467a-8b7c-a524b5c3d285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from distnet import DistResNeXt50\n",
    "from dataset import KITTI,NuScenes\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.patheffects as patheffects\n",
    "import pandas as pd\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87d35be9-499b-4928-9691-8f6ce1ce201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(DistResNeXt50):\n",
    "    def __init__(self, n_classes, image_size, pretrained, keypoints):\n",
    "        super(FeatureExtractor, self).__init__(n_classes, image_size, pretrained, keypoints)\n",
    "    \n",
    "    def forward(self, x, x_boxes):\n",
    "        \n",
    "        # feed entire image thru the backbone\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # perform roi pooling of resnext features\n",
    "        x = self.RoIPool(x, x_boxes)\n",
    "        \n",
    "        # flatten our feature vector\n",
    "        x = x.flatten(start_dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcd31ed-ba13-4f21-a831-63ac6b83d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77c29194-3108-4714-b80f-26d98986f734",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "# split = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6350663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "706639\n"
     ]
    }
   ],
   "source": [
    "# create our transforms routine\n",
    "size=1024\n",
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                             torchvision.transforms.Normalize(\n",
    "                                                 mean=[0.485, 0.456, 0.406],\n",
    "                                                 std=[0.229, 0.224, 0.225]\n",
    "                                             )\n",
    "                                            ])\n",
    "\n",
    "# create test dataset and loader\n",
    "dataset = NuScenes(img_dir='/irad_mounts/lambda-quad-5-data/beholder/intern_data/nuscenes-full/',\n",
    "                          meta_path='/irad_mounts/lambda-quad-5-data/beholder/intern_data/nuscenes-full/nuscenes-v1.0.csv',\n",
    "                          split = split,\n",
    "                          transforms = transforms,\n",
    "                          size = size)\n",
    "\n",
    "# 17 classes of objects in nuscenes full dataset\n",
    "n_classes = dataset.n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ffda97f-c6f4-400d-bda2-a4c173b41f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FeatureExtractor(n_classes, size, False, True)\n",
    "model.to(device)\n",
    "# model.load_state_dict(torch.load('/irad_users/determined/checkpoints/82cf578e-200c-4909-b7a4-2324103a0ac1/state_dict.pth')['models_state_dict'][0])\n",
    "# model.load_state_dict(torch.load('/irad_users/determined/checkpoints/52b28b81-b8ae-4af6-ba8d-14220cd649d5/state_dict.pth')['models_state_dict'][0])\n",
    "# model.load_state_dict(torch.load('/irad_users/determined/checkpoints/d5c59a17-dbd6-4809-8d9a-1dc7f4a8e560/state_dict.pth')['models_state_dict'][0])\n",
    "model.load_state_dict(torch.load('/irad_users/determined/checkpoints/1f6a5c6d-bfb9-497e-b27e-baed4b642d39/state_dict.pth')['models_state_dict'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e23348-6989-4fe7-a18c-081d4bc3ff4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/128112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../dataset.py:109: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  data = self.metadata.loc[self.sample_list[idx]]\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47654/128112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# reconstruct dataframe w/ feature vectors added\n",
    "df = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(len(dataset)):\n",
    "        print(f'\\r{i}/{len(dataset)-1}', end='')\n",
    "\n",
    "        # grab the batch and move the batch to the gpu\n",
    "        data = dataset.__getitem__(i)\n",
    "        inputs, boxes, distances, classes = data\n",
    "        inputs = inputs.to(device).unsqueeze(0)\n",
    "        boxes = [boxes.to(device)]\n",
    "\n",
    "        # forward pass\n",
    "        fv = model(inputs, boxes).cpu().numpy()\n",
    "        \n",
    "        classes = classes.cpu().numpy()\n",
    "        \n",
    "        # construct a dictionary for each annotation item\n",
    "        # append it to larger dataframe\n",
    "        distances = distances.cpu().numpy()\n",
    "        for i in range(boxes[0].shape[0]):\n",
    "            bboxes = boxes[0][i].cpu().numpy()\n",
    "            d = {\n",
    "                'boxes_xmin': bboxes[0],\n",
    "                'boxes_ymin': bboxes[1],\n",
    "                'boxes_xmax': bboxes[2],\n",
    "                'boxes_ymax': bboxes[3],\n",
    "                'classes': classes[i],\n",
    "                'feature_vector': fv[i],\n",
    "                'distances': distances[i]\n",
    "            }\n",
    "            df.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6aaed4-c848-45d3-a9b5-7eb200db943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data to csv\n",
    "df = pd.DataFrame(df)\n",
    "df.to_json(f'{split}.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b753365c-b3a7-4d38-821d-ef1dcacfbe40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
