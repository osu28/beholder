{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae02345-c8f4-45ad-b973-72f6713e5985",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in /opt/conda/lib/python3.8/site-packages (1.2.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from albumentations) (1.8.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from albumentations) (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /opt/conda/lib/python3.8/site-packages (from albumentations) (1.22.3)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /opt/conda/lib/python3.8/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from albumentations) (5.4.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /opt/conda/lib/python3.8/site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations) (4.1.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /opt/conda/lib/python3.8/site-packages (from qudida>=0.0.4->albumentations) (1.1.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2.19.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (9.1.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2.8.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.8/site-packages (from scikit-image>=0.16.1->albumentations) (2022.5.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (3.0.8)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations\n",
    "!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3048f80-6e1a-4da9-9d14-cf422c773b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('/irad_users/smithk/beholder-interns/')\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "from determined.pytorch import DataLoader\n",
    "from prettytable import PrettyTable\n",
    "from dataset import NuScenes, KITTI\n",
    "from intern_dataset import InternData\n",
    "from distresnet import DistResNet18\n",
    "from mlpnet import DistanceRegressor\n",
    "from distnet import DistResNeXt50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "604b6961-c8fe-4064-ba95-91a46425d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import (HorizontalFlip,\n",
    "                            HueSaturationValue,\n",
    "                            RandomBrightnessContrast,\n",
    "                            Blur,\n",
    "                            GaussNoise,\n",
    "                            CLAHE,\n",
    "                            CoarseDropout,\n",
    "                            RGBShift,\n",
    "                            BboxParams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "993fd70c-7050-409b-85a0-b862946bab76",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                          torchvision.transforms.Normalize(\n",
    "                                                              mean=[0.485, 0.456, 0.406],\n",
    "                                                              std=[0.229, 0.224, 0.225]\n",
    "                                                          )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d2c058-ec82-458b-b076-292f0afe3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = NuScenes(img_dir='/irad_mounts/lambda-quad-5-data/beholder/intern_data/nuscenes-full/',\n",
    "                                  meta_path='/irad_mounts/lambda-quad-5-data/beholder/intern_data/nuscenes-full/nuscenes-v1.0.csv',\n",
    "                                  split = 'test',\n",
    "                                  augs = None,\n",
    "                                  transforms = transforms,\n",
    "                                  size = 1024,\n",
    "                                  map_to_kitti=True\n",
    "                                  )\n",
    "\n",
    "\n",
    "testloader = DataLoader(test_data,\n",
    "                        batch_size=1,\n",
    "                        drop_last=True,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=test_data.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b19c51a-abaf-48aa-a3f7-d6a484e3796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_mlp = NuScenes(img_dir='/irad_mounts/lambda-quad-5-data/beholder/intern_data/nuscenes-full/',\n",
    "                                  meta_path='/irad_mounts/lambda-quad-5-data/beholder/intern_data/nuscenes-full/nuscenes-v1.0.csv',\n",
    "                                  split = 'test',\n",
    "                                  augs = None,\n",
    "                                  transforms = transforms,\n",
    "                                  size = 1024,\n",
    "                                  map_to_kitti=True,\n",
    "                                  mlp = True\n",
    "                                  )\n",
    "testloader_mlp = DataLoader(test_data_mlp,\n",
    "                        batch_size=1,\n",
    "                        drop_last=True,\n",
    "                        shuffle=False,\n",
    "                        collate_fn=test_data.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1786fd42-b680-49ab-96ee-8da832bc9303",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "697bce7e-c5b0-45e2-8224-20b7ec5e16d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f87ad045-6d60-48c9-8ad1-c6bf5b5c1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnext = DistResNeXt50(8, image_size=1024, pretrained=False, keypoints=False)\n",
    "model_pth = \"/irad_users/determined/checkpoints/3300d9d6-f061-419c-9b92-84ee6f6d7253/state_dict.pth\"\n",
    "resnext.load_state_dict(torch.load(model_pth)['models_state_dict'][0], strict=False)\n",
    "resnext.to(device)\n",
    "models['resnext'] = {'name': 'resnext', 'model': resnext}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e33c3886-5863-4ce5-819a-c01d7141d17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = DistResNet18(8, image_size=1024, pretrained=False,keypoints=False)\n",
    "model_pth = \"/irad_users/determined/checkpoints/90dab9a5-24cb-4ba2-8e49-db24e8f12d7c/state_dict.pth\"\n",
    "resnet.load_state_dict(torch.load(model_pth)['models_state_dict'][0], strict=False)\n",
    "resnet.to(device)\n",
    "models['resnet'] = {'name': 'resnet', 'model': resnet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e33cfd7-ef45-4432-a3e7-89fd6c765964",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = DistanceRegressor(n_features= 10)\n",
    "model_pth = \"/irad_users/determined/checkpoints/90dab9a5-24cb-4ba2-8e49-db24e8f12d7c/state_dict.pth\"\n",
    "mlp.load_state_dict(torch.load(model_pth)['models_state_dict'][0], strict=False)\n",
    "mlp.to(device)\n",
    "models['mlp'] = {'name': 'mlp', 'model': mlp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "702d27c9-d8b0-42a4-ac91-d0d66d1b9e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://deci.ai/blog/measure-inference-time-deep-neural-networks/\n",
    "starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "for model_dict in models:\n",
    "\n",
    "    model = models[model_dict]['model']\n",
    "    num_res = 300\n",
    "    timings=np.zeros((num_res,1))\n",
    "    \n",
    "    if model_dict == 'mlp':\n",
    "        data = testloader_mlp\n",
    "    else:\n",
    "        data = testloader\n",
    "\n",
    "    for i,batch in enumerate(data):\n",
    "        # MEASURE PERFORMANCE\n",
    "        inputs,boxes,distances,classes = batch[0],batch[1],batch[2],batch[3]\n",
    "        inputs = inputs.to(device)\n",
    "        boxes = [b.to(device) for b in boxes]\n",
    "        classes = [c.to(device) for c in classes]\n",
    "\n",
    "        # GPU warmup \n",
    "        if i < 5: \n",
    "            if model_dict != 'mlp':\n",
    "                _ = model(inputs,boxes)\n",
    "            else:\n",
    "                inputs = torch.cat([torch.cat([bbox, class_encoding], dim=1) for bbox, class_encoding in zip(boxes, classes)])\n",
    "                _ = model(inputs)\n",
    "        with torch.no_grad():\n",
    "            starter.record()\n",
    "            if model_dict != 'mlp':\n",
    "                _ = model(inputs,boxes)\n",
    "            else:\n",
    "                inputs = torch.cat([torch.cat([bbox, class_encoding], dim=1) for bbox, class_encoding in zip(boxes, classes)])\n",
    "                _ = model(inputs)\n",
    "            ender.record()\n",
    "            # WAIT FOR GPU SYNC\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[i] = curr_time\n",
    "            if i >= num_res - 1:\n",
    "                break\n",
    "    mean_syn = np.sum(timings) / num_res\n",
    "    std_syn = np.std(timings)\n",
    "    models[model_dict]['time']=mean_syn\n",
    "    models[model_dict]['std']=std_syn\n",
    "    models[model_dict]['num_features'] = sum(dict((p.data_ptr(), p.numel()) for p in model.parameters()).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4aeb272-a403-4fc7-87f6-b9c0677a07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = PrettyTable(['Model','Time (ms)','Std Deviation', 'Num Features'])\n",
    "table = []\n",
    "for model in models:\n",
    "    table.append([models[model]['name'],models[model]['time'], models[model]['std'],models[model]['num_features']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9104533-58aa-43e3-8920-1500cb053c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------------+----------------------+--------------+\n",
      "|  Model  |      Time (ms)      |    Std Deviation     | Num Features |\n",
      "+---------+---------------------+----------------------+--------------+\n",
      "| resnext |  27.351108601888022 | 0.30467881008816694  |   23644489   |\n",
      "|  resnet |   8.14128205458323  | 0.41680646480497224  |   11312201   |\n",
      "|   mlp   | 0.42664693256219227 | 0.027961753210412506 |   2792577    |\n",
      "+---------+---------------------+----------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "tab.add_rows(table)\n",
    "print(tab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
